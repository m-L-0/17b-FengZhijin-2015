{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/fashion/t10k-labels-idx1-ubyte.gz\n",
      "After 0 training step(s), validation accuracy using average model is 0.0696 \n",
      "After 1000 training step(s), validation accuracy using average model is 0.8516 \n",
      "After 2000 training step(s), validation accuracy using average model is 0.8752 \n",
      "After 3000 training step(s), validation accuracy using average model is 0.8532 \n",
      "After 4000 training step(s), validation accuracy using average model is 0.8894 \n",
      "After 5000 training step(s), validation accuracy using average model is 0.8812 \n",
      "After 6000 training step(s), validation accuracy using average model is 0.8826 \n",
      "After 7000 training step(s), validation accuracy using average model is 0.8908 \n",
      "After 8000 training step(s), validation accuracy using average model is 0.8864 \n",
      "After 9000 training step(s), validation accuracy using average model is 0.8884 \n",
      "After 10000 training step(s), validation accuracy using average model is 0.8992 \n",
      "After 11000 training step(s), validation accuracy using average model is 0.8968 \n",
      "After 12000 training step(s), validation accuracy using average model is 0.8946 \n",
      "After 13000 training step(s), validation accuracy using average model is 0.8908 \n",
      "After 14000 training step(s), validation accuracy using average model is 0.8936 \n",
      "After 15000 training step(s), validation accuracy using average model is 0.8976 \n",
      "After 16000 training step(s), validation accuracy using average model is 0.8986 \n",
      "After 17000 training step(s), validation accuracy using average model is 0.8918 \n",
      "After 18000 training step(s), validation accuracy using average model is 0.8912 \n",
      "After 19000 training step(s), validation accuracy using average model is 0.8992 \n",
      "After 20000 training step(s), validation accuracy using average model is 0.8962 \n",
      "After 21000 training step(s), validation accuracy using average model is 0.895 \n",
      "After 22000 training step(s), validation accuracy using average model is 0.8984 \n",
      "After 23000 training step(s), validation accuracy using average model is 0.8994 \n",
      "After 24000 training step(s), validation accuracy using average model is 0.9008 \n",
      "After 25000 training step(s), validation accuracy using average model is 0.9018 \n",
      "After 26000 training step(s), validation accuracy using average model is 0.9034 \n",
      "After 27000 training step(s), validation accuracy using average model is 0.9034 \n",
      "After 28000 training step(s), validation accuracy using average model is 0.8976 \n",
      "After 29000 training step(s), validation accuracy using average model is 0.9008 \n",
      "After 30000 training step(s), test accuracy using average model is 0.8939\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "# author: Fengzhijin\n",
    "# time: 2017.11.16\n",
    "# ==================================\n",
    "'''\n",
    "运用神经网络解决FashionMNIST数据识别问题\n",
    "1.get_weights_bases() - 生成各层权值及偏置值函数\n",
    "2.hidden_inference() - 隐藏层计算函数\n",
    "3.inference() - 输构建两层神经网络结构函数\n",
    "4.train() - 神经网络训练\n",
    "5.此算法对模型正确率加入了可视化\n",
    "'''\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 模型相关的参数\n",
    "LEARNING_RATE_BASE = 0.1    # 初始化的学习率\n",
    "LEARNING_RATE_DECAY = 0.99    # 学习率的衰减率\n",
    "BATCH_SIZE = 100     # 每次batch打包的样本个数\n",
    "TRAINING_STEPS = 30000    # 训练轮数\n",
    "\n",
    "# 配置神经网络的参数\n",
    "INPUT_NODE = 784     # 输入层的节点数\n",
    "OUTPUT_NODE = 10     # 输出层的节点数\n",
    "LAYER1_NODE = 784    # 隐藏层一节点数，有784个节点\n",
    "LAYER2_NODE = 100    # 隐藏层二节点数，有100个节点\n",
    "REGULARAZTION_RATE = 0.0001    # 描述模型复杂度的正则化项在损失函数中的系数\n",
    "\n",
    "\n",
    "# 生成各层权值和偏置值\n",
    "def get_weights_bases(shape):\n",
    "    weights = tf.Variable(tf.truncated_normal([shape[0], shape[1]], stddev=0.1))\n",
    "    bases = tf.Variable(tf.constant(0.1, shape=[shape[1]]))\n",
    "    return weights, bases\n",
    "\n",
    "\n",
    "# 隐藏层运算\n",
    "def hidden_inference(input_tensor, weights, biases):\n",
    "    layer = tf.nn.relu(tf.matmul(input_tensor, weights) + biases)\n",
    "    return layer\n",
    "\n",
    "\n",
    "# 输出层运算\n",
    "def output_inference(input_tensor, weights, biases):\n",
    "    layer = tf.matmul(input_tensor, weights) + biases\n",
    "    return layer\n",
    "\n",
    "\n",
    "# 构建两层神经网络模型\n",
    "def inference(x, y_, variable_averages=None):\n",
    "    # 生成隐藏层1的参数。\n",
    "    weights1, biases1 = get_weights_bases([INPUT_NODE, LAYER1_NODE])\n",
    "    # 生成隐藏层2的参数。\n",
    "    weights2, biases2 = get_weights_bases([LAYER1_NODE, LAYER2_NODE])\n",
    "    # 生成输出层的参数。\n",
    "    weights3, biases3 = get_weights_bases([LAYER2_NODE, OUTPUT_NODE])\n",
    "    # 隐藏层1的输出\n",
    "    y1 = hidden_inference(x, weights1, biases1)\n",
    "    # 隐藏层2的输出\n",
    "    y2 = hidden_inference(y1, weights2, biases2)\n",
    "    # 输出层结果\n",
    "    y = output_inference(y2, weights3, biases3)\n",
    "    # 使用TensorFlow中提供的sparse_softmax_cross_entropy_with_logits函数来计算交叉熵\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "    # 计算当前batch中所有样例的交叉熵平均值\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    # 计算L2正则化损失函数\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n",
    "    # 计算模型的正则化损失。一般只计算神经网络边上权重的正则化损失，而不是用偏置项\n",
    "    regularaztion = regularizer(weights1) + regularizer(weights2) + regularizer(weights3)\n",
    "    # 总损失等于交叉熵损失和正则化损失的总和\n",
    "    loss = cross_entropy_mean + regularaztion\n",
    "    return y, loss\n",
    "\n",
    "\n",
    "def train(mnist):\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # 生成输入数据集和标签集\n",
    "        x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n",
    "        y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n",
    "        # 定义存储训练轮数的变量\n",
    "        global_step = tf.Variable(0)\n",
    "        # 计算前向传播结果和损失函数\n",
    "        y, loss = inference(x, y_)\n",
    "\n",
    "        # 设置指数衰减的学习率。\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            LEARNING_RATE_BASE,    # 初始化的学习率，随着迭代的进行，更新变量时使用的学习率在这个基础上递减\n",
    "            global_step,    # 当前迭代的轮数\n",
    "            mnist.train.num_examples / BATCH_SIZE,    # 过完所有的训练数据需要的迭代次数\n",
    "            LEARNING_RATE_DECAY)    # 学习率衰减速度\n",
    "\n",
    "        # 使用梯度下降优化算法来优化损失函数\n",
    "        # train_step = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(loss, global_step=global_step)\n",
    "        train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(\n",
    "            loss, global_step=global_step)\n",
    "        # train_step = tf.train.AdamOptimizer().minimize(loss, global_step=global_step)\n",
    "\n",
    "        # 更新神经网络中的参数\n",
    "        with tf.control_dependencies([train_step]):\n",
    "            train_op = tf.no_op(name='train')\n",
    "\n",
    "        # 检验神经网络前向传播结果是否正确\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "        # 计算这一组数据上的正确率\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        # 将accuracy正确率在tensorboard的SCALAR、HISTOGRAM面板上创建可视化摘要\n",
    "        summary_op = tf.summary.scalar('value', accuracy)\n",
    "        histogram = tf.summary.histogram('histogram', accuracy)\n",
    "\n",
    "    # 初始化回话并开始训练过程。\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        # 创建事件文件\n",
    "        writer = tf.summary.FileWriter('./graphs')\n",
    "        writer.add_graph(graph)\n",
    "        # 初始化所有变量\n",
    "        tf.global_variables_initializer().run()\n",
    "        # 准备验证数据\n",
    "        validate_feed = {x: mnist.validation.images, y_:\n",
    "                         mnist.validation.labels}\n",
    "        # 准备测试数据\n",
    "        test_feed = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "\n",
    "        # 迭代地训练神经网络。\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            # 每1000轮输出一次在验证数据集上的测试结果\n",
    "            if i % 1000 == 0:\n",
    "                # 计算模型验证数据上的正确率\n",
    "                # validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "\n",
    "                # 计算模型在验证数据集上的正确率并运行摘要\n",
    "                summary, acc = sess.run([summary_op, accuracy], feed_dict=validate_feed)\n",
    "                writer.add_summary(summary, i)\n",
    "                summaries = sess.run(histogram, feed_dict=validate_feed)\n",
    "                writer.add_summary(summaries, i)\n",
    "\n",
    "                print(\"After %d training step(s), validation accuracy using average model is %g \" % (i, acc))\n",
    "\n",
    "            # 产生这一轮使用的一个batch的训练数据，并运行训练过程\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={x: xs, y_: ys})\n",
    "        # 在训练结束之后，在测试数据上检测神经网络模型的最终正确率\n",
    "        test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "        print((\"After %d training step(s), test accuracy using average model is %g\" % (TRAINING_STEPS, test_acc)))\n",
    "        # 关闭事件文件\n",
    "        writer.close()\n",
    "\n",
    "\n",
    "# 主程序\n",
    "def main(argv=None):\n",
    "    # 使用tensorflow方法处理数据集\n",
    "    mnist = input_data.read_data_sets(\"../data/fashion\", one_hot=True)\n",
    "    train(mnist)\n",
    "\n",
    "\n",
    "# TensorFlow提供的一个主程序入口\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
