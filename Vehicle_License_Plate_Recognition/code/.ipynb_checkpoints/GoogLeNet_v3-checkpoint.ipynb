{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0190476190476 3.70773\n",
      "1 0.6 1.271\n",
      "2 0.885714285714 0.560518\n",
      "3 0.939682539683 0.363389\n",
      "4 0.939682539683 0.229469\n",
      "5 0.955555555556 0.193268\n",
      "6 0.961904761905 0.123679\n",
      "7 0.971428571429 0.0644708\n",
      "8 0.961904761905 0.0657416\n",
      "9 0.961904761905 0.0510221\n",
      "10 0.971428571429 0.0632319\n",
      "11 0.977777777778 0.013897\n",
      "12 0.974603174603 0.00608422\n",
      "13 0.965079365079 0.0227196\n",
      "14 0.965079365079 0.0295565\n",
      "15 0.977777777778 0.0682702\n",
      "16 0.974603174603 0.00530679\n",
      "17 0.980952380952 0.00840715\n",
      "18 0.980952380952 0.0171064\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4a3855c0f4f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-4a3855c0f4f3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    270\u001b[0m                                  range(batch_size, len(trX)+1, batch_size))\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mtr_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_keep_conv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             accuracy = np.mean(np.argmax(teY, axis=1) == sess.run(\n\u001b[1;32m    274\u001b[0m                  predict_op, feed_dict={X: teX,  p_keep_conv: 1.0}))\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "# author: Fengzhijin\n",
    "# time: 2017.12.5\n",
    "# ==================================\n",
    "'''\n",
    "运用GoogLeNet_v3思想解决车牌字符识别问题\n",
    "1.init_weight() - 生成卷积神经网络卷积核函数\n",
    "2.get_weights_bases() - 生成神经网络各层权值与偏置值函数\n",
    "3.inception_0_module_0() - 构建第一个inception module 模块组第一个inception module函数\n",
    "4.inception_0_module_1() - 构建第一个inception module 模块组第二个inception module函数\n",
    "5.inception_0_module_2() - 构建第一个inception module 模块组第三个inception module函数\n",
    "6.inception_0() - 组合第一个inception module 模块组\n",
    "7.inception_1_module_0() - 构建第二个inception module 模块组第一个inception module函数\n",
    "8.inception_1_module_1() - 构建第二个inception module 模块组第二个inception module函数\n",
    "9.inception_1_module_2() - 构建第二个inception module 模块组第三个inception module函数\n",
    "10.inception_1() - 组合第二个inception module 模块组\n",
    "11.model（）- 模型网络结构\n",
    "12.此算法对过拟合进行解决，模型只保存正确率高的情况\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import graph_util\n",
    "import read_data as rd\n",
    "\n",
    "classes_zimu = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H',\n",
    "                8: 'J', 9: 'K', 10: 'L', 11: 'M', 12: 'N', 13: 'P', 14: 'Q',\n",
    "                15: 'R', 16: 'S', 17: 'T', 18: 'U', 19: 'V', 20: 'W', 21: 'X',\n",
    "                22: 'Y', 23: 'Z'}\n",
    "classes_hanzi = {24: '藏', 25: '川', 26: '鄂', 27: '甘', 28: '赣', 29: '广', 30: '桂',\n",
    "                 31: '贵', 32: '黑', 33: '沪', 34: '吉', 35: '冀', 36: '津', 37: '晋',\n",
    "                 38: '京', 39: '辽', 40: '鲁', 41: '蒙', 42: '闽', 43: '宁', 44: '青',\n",
    "                 45: '琼', 46: '陕', 47: '苏', 48: '皖', 49: '湘', 50: '新', 51: '渝',\n",
    "                 52: '豫', 53: '粤', 54: '云', 55: '浙'}\n",
    "classes_shuzi = {56: '0', 57: '1', 58: '2', 59: '3', 60: '4', 61: '5', 62: '6',\n",
    "                 63: '7', 64: '8', 65: '9'}\n",
    "classes = ['字母', '汉字', '数字']\n",
    "size = 18449\n",
    "validation_size = 315\n",
    "test_size = 630\n",
    "train_size = 17504\n",
    "\n",
    "batch_size = 250\n",
    "\n",
    "MODEL_SAVE_PATH = \"./model/pb/\"\n",
    "\n",
    "\n",
    "def init_weight(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "\n",
    "def get_weights_bases(shape):\n",
    "    weights = tf.Variable(tf.truncated_normal([shape[0], shape[1]], stddev=0.1))\n",
    "    bases = tf.Variable(tf.constant(0.1, shape=[shape[1]]))\n",
    "    return weights, bases\n",
    "\n",
    "\n",
    "def inception_0_module_0(net):\n",
    "    branch_0 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 128, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 128, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(branch_1, init_weight([3, 3, 32, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 128, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(branch_2, init_weight([3, 3, 32, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(branch_2, init_weight([3, 3, 32, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "\n",
    "    branch_3 = tf.nn.avg_pool(net, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1],\n",
    "                              padding='SAME')\n",
    "    branch_3 = tf.nn.relu(tf.nn.conv2d(branch_3, init_weight([3, 3, 128, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "\n",
    "    return tf.concat([branch_0, branch_1, branch_2, branch_3], 3)\n",
    "    # shape = [?, 24, 12, 128]\n",
    "\n",
    "\n",
    "def inception_0_module_1(net):\n",
    "    branch_0 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 128, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 128, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(branch_1, init_weight([3, 3, 32, 64]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 128, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(branch_2, init_weight([3, 3, 32, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(branch_2, init_weight([3, 3, 32, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "\n",
    "    branch_3 = tf.nn.avg_pool(net, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1],\n",
    "                              padding='SAME')\n",
    "    branch_3 = tf.nn.relu(tf.nn.conv2d(branch_3, init_weight([3, 3, 128, 64]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "\n",
    "    return tf.concat([branch_0, branch_1, branch_2, branch_3], 3)\n",
    "    # shape = [?, 24, 12, 192]\n",
    "\n",
    "\n",
    "def inception_0_module_2(net):\n",
    "    branch_0 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 128, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 128, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(branch_1, init_weight([3, 3, 32, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 128, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(branch_2, init_weight([3, 3, 32, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(branch_2, init_weight([3, 3, 32, 32]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "\n",
    "    branch_3 = tf.nn.avg_pool(net, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1],\n",
    "                              padding='SAME')\n",
    "    branch_3 = tf.nn.relu(tf.nn.conv2d(branch_3, init_weight([3, 3, 128, 64]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "\n",
    "    return tf.concat([branch_0, branch_1, branch_2, branch_3], 3)\n",
    "    # shape = [?, 24, 12, 160]\n",
    "\n",
    "\n",
    "def inception_0(net):\n",
    "    return tf.concat([inception_0_module_0(net), inception_0_module_1(net),\n",
    "                     inception_0_module_2(net)], 3)\n",
    "    # shape = [?, 24, 12, 480]\n",
    "\n",
    "\n",
    "def inception_1_module_0(net):\n",
    "    branch_0 = tf.nn.relu(tf.nn.conv2d(net, init_weight([3, 3, 480, 64]),\n",
    "                          strides=[1, 2, 2, 1], padding='VALID'))\n",
    "    # shape = [?, 11, 5, 64]\n",
    "\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 480, 128]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(branch_1, init_weight([3, 3, 128, 64]),\n",
    "                          strides=[1, 2, 2, 1], padding='VALID'))\n",
    "    # shape = [?, 11, 5, 64]\n",
    "\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 480, 256]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(branch_2, init_weight([3, 3, 256, 128]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(branch_2, init_weight([3, 3, 128, 64]),\n",
    "                          strides=[1, 2, 2, 1], padding='VALID'))\n",
    "    # shape = [?, 11, 5, 64]\n",
    "\n",
    "    branch_3 = tf.nn.max_pool(net, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                              padding='VALID')\n",
    "    branch_3 = tf.nn.relu(tf.nn.conv2d(branch_3, init_weight([1, 1, 480, 128]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    # shape = [?, 11, 5, 128]\n",
    "\n",
    "    return tf.concat([branch_0, branch_1, branch_2, branch_3], 3)\n",
    "    # shape = [?, 11, 5, 320]\n",
    "\n",
    "\n",
    "def inception_1_module_1(net):\n",
    "    branch_0 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 480, 64]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    # shape = [?, 24, 12, 64]\n",
    "\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 480, 256]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(branch_1, init_weight([1, 5, 256, 128]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(branch_1, init_weight([5, 1, 128, 64]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    # shape = [?, 24, 12, 64]\n",
    "\n",
    "    branch_2 = tf.concat([\n",
    "        tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 3, 480, 64]),\n",
    "                   strides=[1, 1, 1, 1], padding='SAME')),\n",
    "        tf.nn.relu(tf.nn.conv2d(net, init_weight([3, 1, 480, 64]),\n",
    "                   strides=[1, 1, 1, 1], padding='SAME'))],\n",
    "        3)\n",
    "    # shape = [?, 24, 12, 128]\n",
    "\n",
    "    return(tf.nn.avg_pool(tf.concat([branch_0, branch_1, branch_2], 3),\n",
    "                          ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                          padding=\"VALID\"))\n",
    "    # shape = [?, 11, 5, 256]\n",
    "\n",
    "\n",
    "def inception_1_module_2(net):\n",
    "\n",
    "    branch_0 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 480, 256]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_0 = tf.nn.relu(tf.nn.conv2d(branch_0, init_weight([3, 3, 256, 64]),\n",
    "                          strides=[1, 2, 2, 1], padding='VALID'))\n",
    "    branch_0 = tf.nn.avg_pool(branch_0, ksize=[1, 3, 3, 1],\n",
    "                              strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    # shape = [?, 11, 5, 64]\n",
    "\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 480, 256]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(branch_1, init_weight([1, 3, 256, 128]),\n",
    "                          strides=[1, 1, 2, 1], padding='VALID'))\n",
    "    branch_1 = tf.nn.relu(tf.nn.conv2d(branch_1, init_weight([3, 1, 128, 64]),\n",
    "                          strides=[1, 2, 1, 1], padding='VALID'))\n",
    "    # shape = [?, 11, 5, 64]\n",
    "\n",
    "    branch_2 = tf.nn.relu(tf.nn.conv2d(net, init_weight([1, 1, 480, 128]),\n",
    "                          strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    branch_2 = tf.nn.max_pool(branch_2, ksize=[1, 3, 3, 1],\n",
    "                              strides=[1, 2, 2, 1], padding='VALID')\n",
    "    # shape = [?, 11, 5, 128]\n",
    "\n",
    "    return tf.concat([branch_0, branch_1, branch_2], 3)\n",
    "    # shape = [?, 11, 5, 256]\n",
    "\n",
    "\n",
    "def inception_1(net):\n",
    "    return tf.concat([inception_1_module_0(net),\n",
    "                      inception_1_module_1(net),\n",
    "                      inception_1_module_2(net)], 3)\n",
    "    # shape = [?, 11, 5 , 832]\n",
    "\n",
    "\n",
    "def model(X, w, b, p_keep_conv):\n",
    "    l1 = tf.nn.relu(tf.nn.conv2d(X, init_weight([3, 3, 3, 32]),\n",
    "                    strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    l1 = tf.nn.dropout(l1, p_keep_conv)\n",
    "    # shape = [?, 48, 24, 32]\n",
    "\n",
    "    l2 = tf.nn.relu(tf.nn.conv2d(l1, init_weight([3, 3, 32, 64]),\n",
    "                    strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    l2 = tf.nn.dropout(l2, p_keep_conv)\n",
    "    # shape = [?, 48, 24, 64]\n",
    "\n",
    "    l3 = tf.nn.max_pool(l2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                        padding='SAME')\n",
    "    l3 = tf.nn.dropout(l3, p_keep_conv)\n",
    "    # shape = [?, 24, 12, 64]\n",
    "\n",
    "    l4 = tf.nn.relu(tf.nn.conv2d(l3, init_weight([1, 1, 64, 64]),\n",
    "                    strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    l4 = tf.nn.dropout(l4, p_keep_conv)\n",
    "    # shape = [?, 24, 12, 64]\n",
    "\n",
    "    l5 = tf.nn.relu(tf.nn.conv2d(l4, init_weight([3, 3, 64, 128]),\n",
    "                    strides=[1, 1, 1, 1], padding='SAME'))\n",
    "    l5 = tf.nn.dropout(l5, p_keep_conv)\n",
    "    # shape = [?, 24, 12, 128]\n",
    "    # l5 = tf.reshape(l5, [-1, w3.get_shape().as_list()[0]])\n",
    "\n",
    "    l6 = inception_0(l5)\n",
    "    l6 = tf.nn.dropout(l6, p_keep_conv)\n",
    "\n",
    "    l7 = inception_1(l6)\n",
    "    l7 = tf.nn.dropout(l7, p_keep_conv)\n",
    "    l7 = tf.reshape(l7, [-1, w.get_shape().as_list()[0]])\n",
    "\n",
    "    layer = tf.matmul(l7, w) + b\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def main():\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        trX, trY = rd.get_train()\n",
    "        teX, teY = rd.get_validation()\n",
    "        X = tf.placeholder(\"float\", [None, 48, 24, 3], name='x-input')\n",
    "        Y = tf.placeholder(\"float\", [None, 66], name='y-input')\n",
    "        w, b = get_weights_bases([11*5*832, 66])\n",
    "        p_keep_conv = tf.placeholder(\"float\", name='p_keep_conv')\n",
    "        py_x = model(X, w, b, p_keep_conv)\n",
    "\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y))\n",
    "        train_op = tf.train.AdamOptimizer().minimize(cost)\n",
    "        predict_op = tf.argmax(py_x, 1)\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        max_acc = 0.\n",
    "        for i in range(30):\n",
    "            training_batch = zip(range(0, len(trX), batch_size),\n",
    "                                 range(batch_size, len(trX)+1, batch_size))\n",
    "            for start, end in training_batch:\n",
    "                tr_op, loss = sess.run([train_op, cost], feed_dict={X: trX[start:end], Y: trY[start:end], p_keep_conv: 0.8})\n",
    "            accuracy = np.mean(np.argmax(teY, axis=1) == sess.run(\n",
    "                 predict_op, feed_dict={X: teX,  p_keep_conv: 1.0}))\n",
    "            print(i, accuracy, loss)\n",
    "            if (accuracy > max_acc):\n",
    "                max_acc = accuracy\n",
    "                new_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names=['ArgMax'])\n",
    "                tf.train.write_graph(new_graph, MODEL_SAVE_PATH, 'GoogLeNet_v3_graph.pb', as_text=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
